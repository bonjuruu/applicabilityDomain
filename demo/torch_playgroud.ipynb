{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# External\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local\n",
    "from adad.utils import drop_redundant_col, maccs2binary, time2str\n",
    "from adad.torch_utils import evaluate, train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukec/workspace/applicabilityDomain\n",
      "Labels: [0 1]\n",
      "Shape: (6018, 167)\n"
     ]
    }
   ],
   "source": [
    "PATH_ROOT = Path(os.getcwd()).absolute().parent\n",
    "print(PATH_ROOT)\n",
    "\n",
    "file_data = os.path.join(PATH_ROOT, \"data\", \"distinct_maccs\", \"Ames_dist_MACCS.csv\")\n",
    "file_idx_train = os.path.join(PATH_ROOT, \"data\", \"distinct_cv\", \"Ames_cv_train.csv\")\n",
    "file_idx_test = os.path.join(PATH_ROOT, \"data\", \"distinct_cv\", \"Ames_cv_test.csv\")\n",
    "\n",
    "idx_train = pd.read_csv(file_idx_train, dtype=pd.Int64Dtype())\n",
    "idx_test = pd.read_csv(file_idx_test, dtype=pd.Int64Dtype())\n",
    "\n",
    "data = pd.read_csv(file_data)\n",
    "data[\"y\"] = data[\"y\"].astype(\"category\").cat.codes\n",
    "print(\"Labels:\", data[\"y\"].unique())\n",
    "print(\"Shape:\", data.shape)\n",
    "\n",
    "# Checking each CV set\n",
    "for c in idx_train.columns:\n",
    "    _i_test = idx_test[c].dropna(axis=0).to_numpy().astype(int)\n",
    "    _i_train = idx_train[c].dropna(axis=0).to_numpy().astype(int)\n",
    "    assert not np.all(np.isin(_i_test, _i_train))\n",
    "    _n_samples = len(_i_train) + len(_i_test)\n",
    "    assert _n_samples == data.shape[0], f\"{_n_samples} != {data.shape[0]}\"\n",
    "\n",
    "# Selecting only 1 CV set\n",
    "col = idx_train.columns[0]\n",
    "idx_test = idx_test[col].dropna(axis=0).to_numpy().astype(int)\n",
    "idx_train = idx_train[col].dropna(axis=0).to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['y'].to_numpy().astype(int)\n",
    "\n",
    "# Drop columns with no information for training.\n",
    "data = drop_redundant_col(data)\n",
    "X = data.drop(['y'], axis=1).to_numpy()\n",
    "\n",
    "# Change any value greater than 1 to 1\n",
    "X = maccs2binary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4814, 154) (1204, 154)\n",
      "(4814,) (1204,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X[idx_train], X[idx_test]\n",
    "y_train, y_test = y[idx_train], y[idx_test]\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"A simple fullly-connected neural network with 1 hidden-layer\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim=512, output_dim=2):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.layer3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 300\n",
    "\n",
    "dataset_train = TensorDataset(\n",
    "    torch.from_numpy(X_train).type(torch.float32),\n",
    "    torch.from_numpy(y_train).type(torch.int64),\n",
    ")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataset_test = TensorDataset(\n",
    "    torch.from_numpy(X_test).type(torch.float32),\n",
    "    torch.from_numpy(y_test).type(torch.int64),\n",
    ")\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Running on CPU!')\n",
    "n_features = X_train.shape[1]\n",
    "model = SimpleModel(n_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 00h00m02s\n"
     ]
    }
   ],
   "source": [
    "# Train the clean model\n",
    "time_start = time.perf_counter()\n",
    "train_model(model, dataloader_train, optimizer, loss_fn, device, MAX_EPOCHS)\n",
    "time_elapsed = time.perf_counter() - time_start\n",
    "print('Time taken: {}'.format(time2str(time_elapsed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 97.20 loss: 0.057. Test acc: 77.49 loss: 1.288\n"
     ]
    }
   ],
   "source": [
    "acc_train, loss_train = evaluate(dataloader_train, model, loss_fn, device)\n",
    "acc_test, loss_test = evaluate(dataloader_test, model, loss_fn, device)\n",
    "print('Train acc: {:.2f} loss: {:.3f}. Test acc: {:.2f} loss: {:.3f}'.format(\n",
    "    acc_train * 100, loss_train, acc_test * 100, loss_test,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing 1D Convolution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dModel(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(Conv1dModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            n_channels, out_channels=1, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            1, out_channels=1, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        self.fc1 = nn.Linear(39, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Conv1dModel(n_features).to(device)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 00h00m00s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.perf_counter()\n",
    "train_model(model, dataloader_train, optimizer, loss_fn, device, MAX_EPOCHS)\n",
    "time_elapsed = time.perf_counter() - time_start\n",
    "print('Time taken: {}'.format(time2str(time_elapsed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 97.20 loss: 0.057. Test acc: 77.49 loss: 1.285\n"
     ]
    }
   ],
   "source": [
    "acc_train, loss_train = evaluate(dataloader_train, model, loss_fn, device)\n",
    "acc_test, loss_test = evaluate(dataloader_test, model, loss_fn, device)\n",
    "print('Train acc: {:.2f} loss: {:.3f}. Test acc: {:.2f} loss: {:.3f}'.format(\n",
    "    acc_train * 100, loss_train, acc_test * 100, loss_test,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "016355130b3c16c526f1441741bcbcb9475435ab9822383558c43dece6aac7b7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('venv37': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
