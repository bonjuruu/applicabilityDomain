{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4df4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4aa8c6-19a5-423e-b382-fcbf855b5045",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18a2afa9-e116-4c02-8311-c310659f1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seed is 569490\n"
     ]
    }
   ],
   "source": [
    "#Generate seed\n",
    "SEED = np.random.randint(1000, 999999)\n",
    "print(f'The seed is {SEED}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8b29a1-bda7-4a29-8d49-26fe963a9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get file locations\n",
    "PATH_ROOT = Path(os.getcwd()).absolute().parent\n",
    "maccs_dir = os.path.join(PATH_ROOT, 'data', 'maccs')\n",
    "path_output = os.path.join(PATH_ROOT, 'experiments', 'cv_indices')\n",
    "\n",
    "#Used to decide the dataset to create cv's for\n",
    "dataset_names = [\"BBBP\", \"HIV\", \"MUV\", \"SIDER\", \"Tox21\"]\n",
    "\n",
    "#Get MACCS paths depending on which datasets you want the cv for\n",
    "maccs_path = [os.path.join(maccs_dir, x) for x in os.listdir(maccs_dir) if x.split(\"_\")[0] in dataset_names]\n",
    "\n",
    "column_names = [f'cv{i}' for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d4270d-2048-4f6c-8919-708c6b3ad69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cv per dataset\n",
    "for i in range(len(maccs_path)):\n",
    "    #Read csv file\n",
    "    df = pd.read_csv(maccs_path[i])\n",
    "    col = [x for x in df.columns if 'y' in x]\n",
    "    \n",
    "    #Get X and y\n",
    "    y = df[col].to_numpy()\n",
    "    X = df.drop(col, axis=1).to_numpy()\n",
    "    \n",
    "    #Create CV splits\n",
    "    kf = KFold(random_state=SEED, shuffle=True)\n",
    "    splits = kf.split(X)\n",
    "    \n",
    "    #Datafrane for each cv split\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    #Append each cv split to the dataframe\n",
    "    for x_train, x_test in splits:\n",
    "        train_pd = pd.DataFrame(x_train)\n",
    "        test_pd = pd.DataFrame(x_test)\n",
    "\n",
    "        train = pd.concat([train, train_pd], axis=1)\n",
    "        test = pd.concat([test, test_pd], axis=1)\n",
    "    \n",
    "    \n",
    "    train = train.astype(pd.Int64Dtype())\n",
    "    test = test.astype(pd.Int64Dtype())\n",
    "    train.columns = column_names\n",
    "    test.columns = column_names\n",
    "    \n",
    "    #Create csv\n",
    "    train.to_csv(os.path.join(path_output, f'{dataset_names[i]}_cv_train.csv'), index=False)\n",
    "    test.to_csv(os.path.join(path_output, f'{dataset_names[i]}_cv_test.csv'), index=False)\n",
    "    print(f\"Created cv split for {dataset_names[i]}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
